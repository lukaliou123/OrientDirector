"""
AIæœåŠ¡æ¨¡å— - é›†æˆLangchainå’ŒOpenAI
è´Ÿè´£ç”Ÿæˆåœºæ™¯é”è¯„å’Œä¸ªæ€§åŒ–å†…å®¹
æ”¯æŒLangchainå’Œä¼ ç»ŸOpenAIä¸¤ç§æ¨¡å¼
"""

import os
import asyncio
from typing import Dict, List, Optional
from openai import AsyncOpenAI
import google.generativeai as genai
from dotenv import load_dotenv
import logging

# å°è¯•å¯¼å…¥Langchain AIæœåŠ¡
try:
    from langchain_ai_service import get_langchain_ai_service, LangchainAIService
    LANGCHAIN_AVAILABLE = True
except ImportError as e:
    LANGCHAIN_AVAILABLE = False
    logging.warning(f"âš ï¸ Langchainä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»ŸOpenAIæœåŠ¡: {e}")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

logger = logging.getLogger(__name__)

class AIService:
    """AIæœåŠ¡ç±»ï¼Œä¼˜å…ˆä½¿ç”¨Langchainï¼Œå›é€€åˆ°ä¼ ç»ŸAPIè°ƒç”¨"""
    
    def __init__(self):
        self.use_langchain = os.getenv('USE_LANGCHAIN', 'true').lower() == 'true'
        self.ai_provider = os.getenv('AI_PROVIDER', 'openai')

        # ä¼˜å…ˆå°è¯•ä½¿ç”¨Langchain
        self.langchain_service = None
        if LANGCHAIN_AVAILABLE and self.use_langchain:
            try:
                self.langchain_service = get_langchain_ai_service()
                if self.langchain_service:
                    logger.info(f"âœ… AIæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨Langchain + {self.ai_provider.capitalize()}")
                    return
            except Exception as e:
                logger.warning(f"âš ï¸ LangchainæœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»ŸAPI: {e}")

        # å›é€€åˆ°ä¼ ç»ŸAPIå®¢æˆ·ç«¯
        if self.ai_provider == 'gemini':
            self.api_key = os.getenv('GEMINI_API_KEY')
            self.model = os.getenv('GEMINI_MODEL', 'gemini-1.5-flash-latest')
            if not self.api_key:
                raise ValueError("âŒ æœªæ‰¾åˆ°GEMINI_API_KEYç¯å¢ƒå˜é‡")
            genai.configure(api_key=self.api_key)
            self.client = genai.GenerativeModel(self.model)
            logger.info(f"âœ… AIæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ä¼ ç»ŸGemini: {self.model}")
        
        elif self.ai_provider == 'openai':
            self.api_key = os.getenv('OPENAI_API_KEY')
            self.model = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')
            if not self.api_key:
                raise ValueError("âŒ æœªæ‰¾åˆ°OPENAI_API_KEYç¯å¢ƒå˜é‡")
            self.client = AsyncOpenAI(api_key=self.api_key)
            logger.info(f"âœ… AIæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ä¼ ç»ŸOpenAI: {self.model}")
        
        else:
            raise ValueError(f"âŒ ä¸æ”¯æŒçš„AI_PROVIDER: {self.ai_provider}")
    
    async def generate_scene_review(
        self, 
        scene_name: str, 
        scene_description: str, 
        scene_type: str = "è‡ªç„¶æ™¯è§‚",
        user_context: Dict = None
    ) -> Dict[str, str]:
        """
        ç”Ÿæˆåœºæ™¯é”è¯„ï¼ˆä¼˜å…ˆä½¿ç”¨Langchainï¼‰
        
        Args:
            scene_name: åœºæ™¯åç§°
            scene_description: åœºæ™¯æè¿°
            scene_type: åœºæ™¯ç±»å‹
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            åŒ…å«é”è¯„å†…å®¹çš„å­—å…¸
        """
        # ä¼˜å…ˆä½¿ç”¨LangchainæœåŠ¡
        if self.langchain_service:
            try:
                logger.info(f"ğŸš€ ä½¿ç”¨Langchainä¸ºåœºæ™¯ '{scene_name}' ç”Ÿæˆé”è¯„...")
                review_data = await self.langchain_service.generate_scene_review(
                    scene_name=scene_name,
                    scene_description=scene_description,
                    scene_type=scene_type,
                    user_context=user_context
                )
                logger.info(f"âœ… Langchainé”è¯„ç”ŸæˆæˆåŠŸ")
                return review_data
            except Exception as e:
                logger.warning(f"âš ï¸ Langchainé”è¯„ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»ŸAPI: {e}")
        
        # å›é€€åˆ°ä¼ ç»ŸAPIæ–¹æ³•
        logger.info(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨ä¼ ç»Ÿ {self.ai_provider.capitalize()} æ–¹æ³•...")
        try:
            prompt = self._build_review_prompt(scene_name, scene_description, scene_type, user_context)
            logger.info(f"ğŸ¤– ä½¿ç”¨ä¼ ç»Ÿ {self.ai_provider.capitalize()} ä¸ºåœºæ™¯ '{scene_name}' ç”Ÿæˆé”è¯„...")
            logger.info(f"ğŸ” æç¤ºè¯é•¿åº¦: {len(prompt)}å­—ç¬¦")

            if self.ai_provider == 'gemini':
                response = await self.client.generate_content_async(prompt)
                content = response.text.strip()
            else: # openai
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ—…æ¸¸è¾¾äººå’Œæ–‡æ¡ˆä¸“å®¶ï¼Œæ“…é•¿ä¸ºå„ç§æ™¯ç‚¹å†™å‡ºæœ‰è¶£ã€ä¸ªæ€§åŒ–çš„é”è¯„ã€‚ä½ çš„è¯„ä»·é£æ ¼å¹½é»˜é£è¶£ï¼Œæ—¢æœ‰ä¸“ä¸šçŸ¥è¯†åˆè´´è¿‘ç”¨æˆ·ä½“éªŒã€‚"
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    max_tokens=500  # æ³¨æ„: gemini-1.5-flash-latest çš„ max_output_tokens åœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶è®¾ç½®
                )
                content = response.choices[0].message.content.strip()

            # è°ƒè¯•ï¼šæ˜¾ç¤ºAIåŸå§‹è¿”å›å†…å®¹
            logger.info(f"ğŸ” ===== {self.ai_provider.upper()}åŸå§‹è¾“å‡º =====")
            logger.info(f"å†…å®¹é•¿åº¦: {len(content)}å­—ç¬¦")
            logger.info(f"åŸå§‹å†…å®¹: <<<{content}>>>")
            logger.info(f"================================")
            
            # è§£æAIè¿”å›çš„ç»“æ„åŒ–å†…å®¹
            review_data = self._parse_ai_response(content)
            
            logger.info(f"âœ… ä¼ ç»Ÿ {self.ai_provider.capitalize()} é”è¯„ç”ŸæˆæˆåŠŸ: {len(content)}å­—ç¬¦")
            return review_data
            
        except Exception as e:
            logger.error(f"âŒ AIé”è¯„ç”Ÿæˆå¤±è´¥: {str(e)}")
            # è¿”å›å¤‡ç”¨å†…å®¹
            return self._get_fallback_review(scene_name, scene_description, scene_type)
    
    def _build_review_prompt(self, scene_name: str, scene_description: str, scene_type: str, user_context: Dict = None) -> str:
        """æ„å»ºé”è¯„ç”Ÿæˆçš„æç¤ºè¯"""
        
        base_prompt = f"""
è¯·ä¸ºä»¥ä¸‹æ™¯ç‚¹ç”Ÿæˆä¸€ä¸ªæœ‰è¶£çš„é”è¯„ï¼š

**æ™¯ç‚¹åç§°**: {scene_name}
**æ™¯ç‚¹ç±»å‹**: {scene_type}  
**æ™¯ç‚¹æè¿°**: {scene_description}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›é”è¯„å†…å®¹ï¼š
{{
    "title": "é”è¯„æ ‡é¢˜ï¼ˆç®€çŸ­æœ‰è¶£ï¼‰",
    "review": "ä¸»è¦é”è¯„å†…å®¹ï¼ˆ100-200å­—ï¼Œé£è¶£å¹½é»˜ä½†ä¸å¤±ä¸“ä¸šï¼‰",
    "highlights": ["äº®ç‚¹1", "äº®ç‚¹2", "äº®ç‚¹3"],
    "tips": "å®ç”¨å°è´´å£«ï¼ˆ50å­—ä»¥å†…ï¼‰",
    "rating_reason": "æ¨èç†ç”±ï¼ˆ30å­—ä»¥å†…ï¼‰",
    "mood": "æ¨èå¿ƒæƒ…ï¼ˆå¦‚ï¼šæ”¾æ¾ã€å†’é™©ã€å­¦ä¹ ã€æ‹ç…§ç­‰ï¼‰"
}}

è¦æ±‚ï¼š
1. è¯­è¨€é£æ ¼è¦è½»æ¾å¹½é»˜ï¼Œåƒæœ‹å‹æ¨èä¸€æ ·
2. çªå‡ºè¿™ä¸ªåœ°æ–¹çš„ç‹¬ç‰¹æ€§å’Œå€¼å¾—å»çš„ç†ç”±
3. å¯ä»¥é€‚å½“è°ƒä¾ƒæˆ–åæ§½ï¼Œä½†è¦æ­£é¢ç§¯æ
4. åŒ…å«å®ç”¨çš„æ¸¸ç©å»ºè®®
5. ä½“ç°èƒŒåŒ…å®¢æ¢ç´¢çš„ç²¾ç¥
"""
        
        # å¦‚æœæœ‰ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ ä¸ªæ€§åŒ–å†…å®¹
        if user_context:
            visit_count = user_context.get('visit_count', 0)
            time_of_day = user_context.get('time_of_day', '')
            previous_places = user_context.get('previous_places', [])
            
            context_info = f"""

**ç”¨æˆ·ä¸Šä¸‹æ–‡**:
- è¿™æ˜¯æ‚¨ä»Šå¤©è®¿é—®çš„ç¬¬{visit_count + 1}ä¸ªåœ°ç‚¹
- å½“å‰æ—¶é—´: {time_of_day}
- ä¹‹å‰è®¿é—®è¿‡: {', '.join(previous_places) if previous_places else 'æ— '}

è¯·ç»“åˆç”¨æˆ·çš„æ¢ç´¢å†ç¨‹ï¼Œè®©é”è¯„æ›´åŠ ä¸ªæ€§åŒ–å’Œè´´åˆå½“å‰çš„æ—…ç¨‹çŠ¶æ€ã€‚
"""
            base_prompt += context_info
        
        return base_prompt
    
    def _parse_ai_response(self, content: str) -> Dict[str, str]:
        """è§£æAIè¿”å›çš„JSONå†…å®¹"""
        try:
            import json
            
            # å°è¯•ç›´æ¥è§£æJSON
            if content.startswith('{') and content.endswith('}'):
                return json.loads(content)
            
            # å°è¯•æå–JSONéƒ¨åˆ†
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            
            if start_idx >= 0 and end_idx > start_idx:
                json_str = content[start_idx:end_idx]
                return json.loads(json_str)
            
            # å¦‚æœæ— æ³•è§£æJSONï¼Œè¿”å›çº¯æ–‡æœ¬æ ¼å¼
            return {
                "title": "AIé”è¯„",
                "review": content,
                "highlights": ["AIç”Ÿæˆå†…å®¹"],
                "tips": "æ¢ç´¢æ„‰å¿«ï¼",
                "rating_reason": "å€¼å¾—ä¸€å»",
                "mood": "æ¢ç´¢"
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ AIå“åº”è§£æå¤±è´¥: {e}")
            return self._get_fallback_review("", content, "")
    
    def _get_fallback_review(self, scene_name: str, scene_description: str, scene_type: str) -> Dict[str, str]:
        """ç”Ÿæˆå¤‡ç”¨é”è¯„å†…å®¹ï¼ˆå½“AIæœåŠ¡ä¸å¯ç”¨æ—¶ï¼‰"""
        return {
            "title": f"æ¢ç´¢å‘ç°ï¼š{scene_name}",
            "review": f"è¿™é‡Œæ˜¯{scene_name}ï¼Œ{scene_description} è™½ç„¶AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä½†è¿™ä¸å½±å“æ‚¨çš„æ¢ç´¢çƒ­æƒ…ï¼æ¯ä¸ªåœ°æ–¹éƒ½æœ‰å…¶ç‹¬ç‰¹çš„é­…åŠ›ç­‰å¾…æ‚¨å»å‘ç°ã€‚",
            "highlights": [
                "çœŸå®åœºæ™¯æ¢ç´¢",
                "ç‹¬ç‰¹åœ°ç†ä½ç½®", 
                "å€¼å¾—è®°å½•çš„æ—¶åˆ»"
            ],
            "tips": "ç”¨å¿ƒæ„Ÿå—æ¯ä¸ªåœ°æ–¹çš„ç‹¬ç‰¹é­…åŠ›",
            "rating_reason": "æ¢ç´¢æœ¬èº«å°±æ˜¯æœ€å¥½çš„ç†ç”±",
            "mood": "å†’é™©"
        }
    
    async def generate_journey_summary_ai(
        self, 
        visited_scenes: List[Dict], 
        total_distance: float, 
        journey_duration: str
    ) -> str:
        """
        ç”ŸæˆAIæ—…ç¨‹æ€»ç»“ï¼ˆä¼˜å…ˆä½¿ç”¨Langchainï¼‰
        
        Args:
            visited_scenes: è®¿é—®çš„åœºæ™¯åˆ—è¡¨
            total_distance: æ€»è·ç¦»
            journey_duration: æ—…ç¨‹æ—¶é•¿
        
        Returns:
            AIç”Ÿæˆçš„æ—…ç¨‹æ€»ç»“æ–‡æœ¬
        """
        # ä¼˜å…ˆä½¿ç”¨LangchainæœåŠ¡
        if self.langchain_service:
            try:
                logger.info(f"ğŸš€ ä½¿ç”¨Langchainç”Ÿæˆæ—…ç¨‹æ€»ç»“...")
                summary_data = await self.langchain_service.generate_journey_summary(
                    visited_scenes=visited_scenes,
                    total_distance=total_distance,
                    journey_duration=journey_duration
                )
                # è¿”å›æ€»ç»“æ–‡æœ¬
                result = summary_data.get('summary', '')
                if summary_data.get('recommendation'):
                    result += f"\n\n{summary_data['recommendation']}"
                logger.info(f"âœ… Langchainæ—…ç¨‹æ€»ç»“ç”ŸæˆæˆåŠŸ")
                return result
            except Exception as e:
                logger.warning(f"âš ï¸ Langchainæ—…ç¨‹æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»ŸAPI: {e}")
        
        # å›é€€åˆ°ä¼ ç»ŸAPIæ–¹æ³•
        try:
            scene_names = [scene.get('name', 'æœªçŸ¥åœ°ç‚¹') for scene in visited_scenes]
            
            prompt = self._build_journey_summary_prompt(visited_scenes, total_distance, journey_duration)
            
            logger.info(f"ğŸ¤– ä½¿ç”¨ä¼ ç»Ÿ {self.ai_provider.capitalize()} ç”Ÿæˆæ—…ç¨‹æ€»ç»“...")

            if self.ai_provider == 'gemini':
                response = await self.client.generate_content_async(prompt)
                result = response.text.strip()
            else: # openai
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä½æ¸©æš–çš„æ—…ç¨‹è®°å½•è€…ï¼Œæ“…é•¿ä¸ºç”¨æˆ·çš„æ¢ç´¢æ—…ç¨‹å†™å‡ºæ„Ÿäººçš„æ€»ç»“ã€‚"
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    max_tokens=2000
                )
                result = response.choices[0].message.content.strip()

            logger.info(f"âœ… ä¼ ç»Ÿ {self.ai_provider.capitalize()} æ—…ç¨‹æ€»ç»“ç”ŸæˆæˆåŠŸ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ AIæ—…ç¨‹æ€»ç»“ç”Ÿæˆå¤±è´¥: {str(e)}")
            return f"ğŸ‰ æ­å–œå®Œæˆè¿™æ¬¡ç²¾å½©çš„æ¢ç´¢ä¹‹æ—…ï¼æ‚¨è®¿é—®äº†{len(visited_scenes)}ä¸ªåœ°ç‚¹ï¼Œæ€»å…±è¡Œè¿›äº†{total_distance:.1f}å…¬é‡Œã€‚æ¯ä¸€æ­¥éƒ½æ˜¯ç‹¬ç‰¹çš„å‘ç°ï¼Œæ¯ä¸€å¤„é£æ™¯éƒ½å€¼å¾—çè—ã€‚æ„Ÿè°¢æ‚¨é€‰æ‹©æ–¹å‘æ¢ç´¢æ´¾å¯¹ï¼ŒæœŸå¾…æ‚¨çš„ä¸‹æ¬¡å†’é™©ï¼ğŸ§­âœ¨"

    def _build_journey_summary_prompt(self, visited_scenes: List[Dict], total_distance: float, journey_duration: str) -> str:
        """æ„å»ºæ—…ç¨‹æ€»ç»“çš„æç¤ºè¯"""
        scene_names = [scene.get('name', 'æœªçŸ¥åœ°ç‚¹') for scene in visited_scenes]
        return f"""
è¯·ä¸ºä»¥ä¸‹æ—…ç¨‹ç”Ÿæˆä¸€ä¸ªæ¸©é¦¨æœ‰è¶£çš„æ€»ç»“ï¼š

**æ—…ç¨‹ä¿¡æ¯**:
- è®¿é—®åœ°ç‚¹: {', '.join(scene_names)}
- æ€»è·ç¦»: {total_distance}å…¬é‡Œ
- æ—…ç¨‹æ—¶é•¿: {journey_duration}
- æ¢ç´¢æ–¹å¼: æ–¹å‘æ¢ç´¢æ´¾å¯¹å·¥å…·

è¯·ç”Ÿæˆä¸€æ®µ100-150å­—çš„æ¸©é¦¨æ€»ç»“ï¼Œè¦æ±‚ï¼š
1. ä½“ç°èƒŒåŒ…å®¢æ¢ç´¢çš„ç²¾ç¥
2. çªå‡ºè¿™æ¬¡æ—…ç¨‹çš„ç‹¬ç‰¹æ€§
3. é¼“åŠ±ç”¨æˆ·ç»§ç»­æ¢ç´¢
4. è¯­è¨€é£æ ¼æ¸©æš–å‹å¥½
5. å¯ä»¥é€‚å½“åŠ å…¥emojiè¡¨æƒ…
"""

# å…¨å±€AIæœåŠ¡å®ä¾‹
ai_service = None

def get_ai_service() -> AIService:
    """è·å–AIæœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global ai_service
    if ai_service is None:
        try:
            ai_service = AIService()
        except Exception as e:
            logger.error(f"âŒ AIæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            ai_service = None
    return ai_service

